{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 20:43:53,305 - Packages imported; ready to begin\n"
     ]
    }
   ],
   "source": [
    "# IMPORT PACKAGES\n",
    "import arcpy\n",
    "from arcpy import metadata as md\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "# ABOUT THE TARGET GEODATABASE\n",
    "sr = arcpy.SpatialReference(3857)\n",
    "\n",
    "fldr = r\"C:\\Users\\Laura\\Documents\\Keepsakes\\Travel\\0_MetadataInstructions\\2022 Database Migration\"\n",
    "name = r\"Travel_Archive\"\n",
    "gdb = name + \".gdb\"\n",
    "\n",
    "# READ IN THE TEMPLATE SPREADSHEET\n",
    "xlsx_fldr = r\"C:\\Users\\Laura\\Documents\\Keepsakes\\Travel\\0_MetadataInstructions\"\n",
    "xlsx_file = r\"Data_Dictionary.xlsx\"\n",
    "xlsx = os.path.join(xlsx_fldr, xlsx_file)\n",
    "\n",
    "# METADATA VARIABLES\n",
    "credits = \"Schema designed and data populated by Laura Kaufmann (lmmk81914@gmail.com)\"\n",
    "constraints = \"Data and schema can only be used with written permission from Laura Kaufmann (lmmk81914@gmail.com)\"\n",
    "\n",
    "# FOLDER OF SQL TXT FILES FOR VIEWS\n",
    "sqlFldr = r\"C:\\Users\\Laura\\Documents\\Keepsakes\\Travel\\0_MetadataInstructions\\ViewSQL\"\n",
    "\n",
    "# FUNCTIONS\n",
    "def getValue(argument):\n",
    "    if argument == 'NONE':\n",
    "        return None\n",
    "    else:\n",
    "        return argument\n",
    "    \n",
    "logging.info('Packages imported; ready to begin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 20:43:59,583 - Blank file geodatabase created\n"
     ]
    }
   ],
   "source": [
    "# DELETE AND CREATE THE TARGET GEODATABASE\n",
    "arcpy.management.Delete(os.path.join(fldr, gdb), '')\n",
    "arcpy.management.CreateFileGDB(fldr, name, \"CURRENT\")\n",
    "\n",
    "wrkspc = os.path.join(fldr, gdb)\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "logging.info('Blank file geodatabase created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\Laura\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "2023-11-07 20:44:10,661 - VoteType_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:44:21,376 - TripStage_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:44:46,235 - DayofWeek_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:45:05,798 - Currency_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:45:31,015 - TicketType_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:46:23,742 - Hour_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:46:37,103 - Minute_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:47:22,906 - LocationType_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:47:33,957 - Interest_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:47:44,921 - YesNoNAUnk_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:47:47,326 - MeasType_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:48:21,999 - Months_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:48:34,963 - MeasUnits_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:48:58,853 - NoteType_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:49:17,002 - TransitDesc_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:49:43,358 - TransitType_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:49:52,356 - Relate_CL domain and values added to the geodatabase\n",
      "2023-11-07 20:50:00,999 - EventType_CL domain and values added to the geodatabase\n"
     ]
    }
   ],
   "source": [
    "# CREATE DOMAINS AND ADD VALUES\n",
    "domains = pd.read_excel(xlsx, sheet_name='Domains')\n",
    "domainValues = pd.read_excel(xlsx, sheet_name='DomainValues')\n",
    "\n",
    "for index, row in domains.iterrows():\n",
    "    domain_name = row['Name']\n",
    "    domain_description = row['Description']\n",
    "    field_type = row['FieldType']\n",
    "    domain_type = row['DomainType']\n",
    "    split_policy = row['SplitPolicy']\n",
    "    merge_policy = row['MergePolicy']\n",
    "\n",
    "    ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/create-domain.htm\n",
    "    arcpy.management.CreateDomain(wrkspc, domain_name, domain_description, field_type, domain_type, split_policy, merge_policy)\n",
    "        \n",
    "    for index, row in domainValues.iterrows():\n",
    "        if row['Name'] == domain_name:\n",
    "            if domain_type == 'CODED':\n",
    "                ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/add-coded-value-to-domain.htm\n",
    "                arcpy.management.AddCodedValueToDomain(wrkspc, domain_name, row['Code'], row['ValueDescription'])\n",
    "            else:\n",
    "                ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/set-value-for-range-domain.htm\n",
    "                arcpy.management.SetValueForRangeDomain(wrkspc, domain_name, row['MinValue'], row['MaxValue'])\n",
    "\n",
    "    logging.info('%s domain and values added to the geodatabase', domain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\Laura\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "2023-11-07 20:50:09,194 - Travelers table created in the geodatabase\n",
      "2023-11-07 20:50:29,649 - Fields added to Travelers\n",
      "2023-11-07 20:50:32,240 - Travelers_Contacts table created in the geodatabase\n",
      "2023-11-07 20:50:44,228 - Fields added to Travelers_Contacts\n",
      "2023-11-07 20:50:46,904 - Travelers_Facts table created in the geodatabase\n",
      "2023-11-07 20:50:54,195 - Fields added to Travelers_Facts\n",
      "2023-11-07 20:50:59,608 - Regions feature class created in the geodatabase\n",
      "2023-11-07 20:51:36,552 - Fields added to Regions\n",
      "2023-11-07 20:51:39,274 - Regions_Countries table created in the geodatabase\n",
      "2023-11-07 20:52:10,978 - Fields added to Regions_Countries\n",
      "2023-11-07 20:52:13,455 - Regions_Averages table created in the geodatabase\n",
      "2023-11-07 20:52:28,790 - Fields added to Regions_Averages\n",
      "2023-11-07 20:52:34,870 - Locations feature class created in the geodatabase\n",
      "2023-11-07 20:53:07,530 - Fields added to Locations\n",
      "2023-11-07 20:53:10,056 - Locations_Hours table created in the geodatabase\n",
      "2023-11-07 20:53:38,886 - Fields added to Locations_Hours\n",
      "2023-11-07 20:53:41,403 - Locations_Notes table created in the geodatabase\n",
      "2023-11-07 20:53:52,892 - Fields added to Locations_Notes\n",
      "2023-11-07 20:53:55,343 - Locations_Tickets table created in the geodatabase\n",
      "2023-11-07 20:54:08,640 - Fields added to Locations_Tickets\n",
      "2023-11-07 20:54:11,037 - Itinerary table created in the geodatabase\n",
      "2023-11-07 20:54:32,668 - Fields added to Itinerary\n",
      "2023-11-07 20:54:35,043 - Transit table created in the geodatabase\n",
      "2023-11-07 20:54:54,055 - Fields added to Transit\n",
      "2023-11-07 20:54:56,345 - SurveyResults table created in the geodatabase\n",
      "2023-11-07 20:55:05,218 - Fields added to SurveyResults\n",
      "2023-11-07 20:55:09,741 - Trips feature class created in the geodatabase\n",
      "2023-11-07 20:55:21,008 - Fields added to Trips\n",
      "2023-11-07 20:55:25,382 - WorldHex15000 feature class created in the geodatabase\n",
      "2023-11-07 20:55:27,455 - Fields added to WorldHex15000\n",
      "2023-11-07 20:55:29,777 - Regions_Taxis table created in the geodatabase\n",
      "2023-11-07 20:55:41,517 - Fields added to Regions_Taxis\n",
      "2023-11-07 20:55:43,746 - SubRegions table created in the geodatabase\n",
      "2023-11-07 20:55:43,751 - Fields added to SubRegions\n",
      "2023-11-07 20:55:45,822 - SubRegion_Match table created in the geodatabase\n",
      "2023-11-07 20:55:45,826 - Fields added to SubRegion_Match\n"
     ]
    }
   ],
   "source": [
    "# CREATE TABLES\n",
    "tables = pd.read_excel(xlsx, sheet_name='Tables')\n",
    "tables = tables.fillna('NONE')\n",
    "\n",
    "fields = pd.read_excel(xlsx, sheet_name='Fields')\n",
    "fields = fields.fillna('NONE')\n",
    "\n",
    "for index, row in tables.iterrows():\n",
    "    \n",
    "    out_name = row['Name']\n",
    "    geometry_type = row['Geometry']\n",
    "    has_m = row['HasM']\n",
    "    has_z = row['HasZ']\n",
    "    summary = row['TableDefinition']\n",
    "    \n",
    "    if row['Module'] == 'None':\n",
    "        tag = geometry_type.capitalize()\n",
    "    else:\n",
    "        tag = \"{}, {}\".format(row['Module'], geometry_type.capitalize())\n",
    "        \n",
    "    if geometry_type == 'TABLE':\n",
    "        ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/create-table.htm\n",
    "        arcpy.management.CreateTable(wrkspc, out_name, None, '', '')\n",
    "        logging.info('%s table created in the geodatabase', out_name)\n",
    "    else:\n",
    "        ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/create-feature-class.htm\n",
    "        arcpy.management.CreateFeatureclass(wrkspc, out_name, geometry_type, None, has_m, has_z, sr)\n",
    "        arcpy.management.RemoveSpatialIndex(os.path.join(wrkspc, out_name))\n",
    "        logging.info('%s feature class created in the geodatabase', out_name)\n",
    "    \n",
    "    mdDesc = []\n",
    "    \n",
    "    for index, row in fields.iterrows():\n",
    "        if row['Table'] == out_name:\n",
    "            \n",
    "            field_name = getValue(row['FieldName'])\n",
    "            field_type = getValue(row['FieldType'])\n",
    "            field_precision = getValue(row['Precision'])\n",
    "            field_scale = getValue(row['Scale'])\n",
    "            field_length = getValue(row['Length'])\n",
    "            field_alias = getValue(row['FieldAlias'])\n",
    "            field_is_nullable = getValue(row['Nullable'])\n",
    "            field_is_required = getValue(row['Required'])\n",
    "            field_domain = getValue(row['FieldDomain'])\n",
    "            field_default = getValue(row['DefaultValue'])\n",
    "            \n",
    "            ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/add-field.htm\n",
    "            arcpy.management.AddField(os.path.join(wrkspc, out_name), field_name, field_type, field_precision, field_scale, field_length, field_alias, field_is_nullable, field_is_required, field_domain)\n",
    "            \n",
    "            if field_default != None:\n",
    "                ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/assign-default-to-field.htm\n",
    "                arcpy.management.AssignDefaultToField(os.path.join(wrkspc, out_name), field_name, field_default)\n",
    "                setDesc = \" (Default: {})\".format(field_default)\n",
    "            \n",
    "            if field_domain != None:\n",
    "                setDesc = \" ({})\".format(field_domain)\n",
    "            \n",
    "            if field_default != None and field_domain != None:\n",
    "                setDesc = \" (Default: {} ({}))\".format(field_default, field_domain)\n",
    "            else:\n",
    "                setDesc = \"\"\n",
    "            \n",
    "            fieldDesc = \"{} ({}) - {}{}\".format(field_name, field_type.capitalize(), row['FieldDefinition'], setDesc)\n",
    "            mdDesc.append(fieldDesc)\n",
    "            \n",
    "    logging.info('Fields added to %s', out_name)\n",
    "    \n",
    "    ##https://pro.arcgis.com/en/pro-app/latest/arcpy/metadata/metadata-class.htm\n",
    "    new_md = md.Metadata()\n",
    "    new_md.title = out_name\n",
    "    new_md.tags = tag\n",
    "    new_md.summary = summary\n",
    "    new_md.description = '\\n'.join(mdDesc)\n",
    "    new_md.credits = credits\n",
    "    new_md.accessConstraints = constraints\n",
    "    \n",
    "    tgt_item_md = md.Metadata(os.path.join(wrkspc, out_name))\n",
    "    if not tgt_item_md.isReadOnly:\n",
    "        tgt_item_md.copy(new_md)\n",
    "        tgt_item_md.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "2023-11-07 20:55:50,639 - Relationship created from Trips to Travelers\n",
      "2023-11-07 20:55:53,948 - Relationship created from Travelers to Travelers_Facts\n",
      "2023-11-07 20:55:57,551 - Relationship created from Travelers to Travelers_Contacts\n",
      "2023-11-07 20:56:01,498 - Relationship created from Trips to WorldHex15000\n",
      "2023-11-07 20:56:05,048 - Relationship created from Trips to Regions\n",
      "2023-11-07 20:56:08,442 - Relationship created from Regions_Countries to Regions\n",
      "2023-11-07 20:56:12,132 - Relationship created from Regions to Regions_Averages\n",
      "2023-11-07 20:56:16,127 - Relationship created from Regions to Locations\n",
      "2023-11-07 20:56:19,578 - Relationship created from Locations to Locations_Hours\n",
      "2023-11-07 20:56:23,363 - Relationship created from Locations to Locations_Tickets\n",
      "2023-11-07 20:56:26,802 - Relationship created from Locations to Locations_Notes\n",
      "2023-11-07 20:56:30,508 - Relationship created from Regions to Regions_Taxis\n",
      "2023-11-07 20:56:34,253 - Relationship created from Locations to Itinerary\n",
      "2023-11-07 20:56:43,037 - Relationship created from Transit to Itinerary\n"
     ]
    }
   ],
   "source": [
    "# RELATIONSHIP CLASSES\n",
    "relationships = pd.read_excel(xlsx, sheet_name='Relationship Classes')\n",
    "relationships = relationships.fillna('NONE')\n",
    "\n",
    "for index, row in relationships.iterrows():\n",
    "    \n",
    "    origin_table = os.path.join(wrkspc, getValue(row['OriginTable']))\n",
    "    destination_table = os.path.join(wrkspc, getValue(row['DestinationTable']))\n",
    "    out_relationship_class = os.path.join(wrkspc, getValue(row['RelationshipClass']))\n",
    "    relationship_type = getValue(row['RelationshipType'])\n",
    "    forward_label = getValue(row['ForwardLabel'])\n",
    "    backward_label = getValue(row['BackwardLabel'])\n",
    "    message_direction = getValue(row['MessageDirection'])\n",
    "    cardinality = getValue(row['Cardinality'])\n",
    "    attributed = getValue(row['Attributed'])\n",
    "    origin_primary_key = getValue(row['O_PrimaryKey'])\n",
    "    origin_foreign_key = getValue(row['O_PrimaryKey'])\n",
    "    destination_primary_key = getValue(row['D_ForeignKey'])\n",
    "    destination_foreign_key = getValue(row['D_ForeignKey'])\n",
    "    \n",
    "    ##https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/create-relationship-class.htm\n",
    "    arcpy.management.CreateRelationshipClass(origin_table, destination_table, out_relationship_class, relationship_type, forward_label, backward_label, message_direction, cardinality, attributed, origin_primary_key, origin_foreign_key, destination_primary_key, destination_foreign_key)\n",
    "    logging.info('Relationship created from %s to %s', row['OriginTable'], row['DestinationTable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# VIEWS\n",
    "views = pd.read_excel(xlsx, sheet_name='Views')\n",
    "views\n",
    "\n",
    "for index, row in views.iterrows():\n",
    "    viewName = \"{}.txt\".format(row['ViewName'])\n",
    "    fileName = os.path.join(sqlFldr, viewName)\n",
    "    \n",
    "    # Open and read the file as a single buffer\n",
    "    file = open(fileName, 'r')\n",
    "    sqlFile = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    print(fileName)\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import OperationalError\n",
    "\n",
    "fileName = r'C:\\Users\\Laura\\Documents\\Keepsakes\\Travel\\0_MetadataInstructions\\ViewSQL\\ActiveRegions.txt'\n",
    "    \n",
    "def executeScriptsFromFile(fileName):\n",
    "    # Open and read the file as a single buffer\n",
    "    fd = open(fileName, 'r')\n",
    "    sqlFile = fd.read()\n",
    "    fd.close()\n",
    "\n",
    "    # all SQL commands (split on ';')\n",
    "    sqlCommands = sqlFile.split(';')\n",
    "\n",
    "    # Execute every command from the input file\n",
    "    for command in sqlCommands:\n",
    "        # This will skip and report errors\n",
    "        # For example, if the tables do not yet exist, this will skip over\n",
    "        # the DROP TABLE commands\n",
    "        try:\n",
    "            c.execute(command)\n",
    "        except OperationalError, msg:\n",
    "            print(\"Command skipped: \", msg)\n",
    "            \n",
    "arcpy.management.RegisterWithGeodatabase(\n",
    "    in_dataset=r\"C:\\Users\\Laura\\AppData\\Roaming\\Esri\\ArcGISPro\\Favorites\\Travel_DEV.sde\\Travel_DEV.dbo.Itinerary_Visits\",\n",
    "    in_object_id_field=\"OBJECTID\",\n",
    "    in_shape_field=\"Shape\",\n",
    "    in_geometry_type=\"POINT\",\n",
    "    in_spatial_reference='PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Mercator_Auxiliary_Sphere\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],PARAMETER[\"Standard_Parallel_1\",0.0],PARAMETER[\"Auxiliary_Sphere_Type\",0.0],UNIT[\"Meter\",1.0]];-20037700 -30241100 10000;-100000 10000;-100000 10000;0.001;0.001;0.001;IsHighPrecision',\n",
    "    in_extent=None\n",
    ")\n",
    "\n",
    "#https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/make-table-view.htm\n",
    "#https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/create-database-view.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
